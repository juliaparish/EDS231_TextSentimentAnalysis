---
title: "Assignment 01: Text Data in R"
author: "Julia Parish"
date: "2022/04/11"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Text Data in R

This text analysis was completed as an assignment for the course, Environmental Data Science 231: Text and Sentiment Analysis for Environmental Problems. The data was sourced from the New York Times using the New York Times API. 

## Load Packages
```{r, message=FALSE}
library(jsonlite) #convert results from API queries into R-friendly formats 
library(tidyverse) 
library(tidytext) #text data management and analysis
library(ggplot2) #plot word frequencies and publication dates
```
## Key Word Selection & Query NY Times API

Pick an interesting environmental key word(s) and use the jsonlite package to query the API. Pick something high profile enough and over a large enough time frame that your query yields enough articles for an interesting examination.

```{r}
# the from JSON flatten the JSON object
coalash <- fromJSON("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=coal+ash&api-key=qUngwwaLSVRerrzAB0TgUdXSHf93H6ea", flatten = TRUE)
```

```{r}
# convert to a data frame
coalash <- coalash %>% 
  data.frame()

#Inspect data
class(coalash) 
dim(coalash) # how big is it? 10 articles, 34 variables

names(coalash) # list of variables
```



## Recreate the publications per day and word frequency plots using the first paragraph


## Make some (at least 3) transformations to the corpus (add stopword(s), stem a key term and its variants, remove numbers)


## Recreate the publications per day and word frequency plots using the headlines variable (response.docs.headline.main). Compare the distributions of word frequencies between the first paragraph and headlines. Do you see any difference?