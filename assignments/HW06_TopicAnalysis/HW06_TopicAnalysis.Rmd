---
title: "Topic 06 - Topic Analysis"
author: "Julia Parish"
date: '2022-05-10'
header-includes:
  - \usepackage{float}
  - \floatplacement{figure}{H}
output: 
  pdf_document:
    extra_dependencies: ["float"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.pos='!H')
```

# Topic Analysis

This text sentiment analysis was completed as an assignment for the course, Environmental Data Science 231: Text and Sentiment Analysis for Environmental Problems. The data was sourced from  ...

Original assignment instructions can be found [here](https://maro406.github.io/EDS_231-text-sentiment/topic_6.html)

### Load Libraries

```{r packages}
#install packages as necessary, then load libraries
if (!require(librarian)){
  install.packages("librarian")
  library(librarian)
}

librarian::shelf(here,
                 igraph,
                 kableExtra,
                 ldatuning,
                 LDAvis,
                 LexisNexisTools,
                 lubridate,
                 pdftools,
                 quanteda,
                 quanteda.textplots,
                 quanteda.textstats,
                 readr,
                 reshape2,
                 sentimentr,
                 tidyr,
                 tidytext,
                 tidyverse,
                 tm,
                 topicmodels,
                 tsne)
```

# Assignment: run three Topic Analysis models and select the overall best value for k (the number of topics).

Include justification for the selection: theory, FindTopicsNumber() optimization metrics, interpretability, LDAvis

### Load the data

```{r}
comments_df <- read_csv(here("assignments/HW06_TopicAnalysis/data/comments_df.csv"))
```

### Create Corpus of EPA Articles

```{r corpus}
epa_corp <- corpus(x = comments_df, text_field = "text")
epa_corp.stats <- summary(epa_corp)

head(epa_corp.stats, n = 15) %>% 
  knitr::kable(caption = "EPA Article Statistics") %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

### Tokenize Corpus

```{r}
toks <- tokens(epa_corp, remove_punct = TRUE, remove_numbers = TRUE)

# project-specific stop words here
add_stops <- c(stopwords("en"),"environmental", "justice", "ej", "epa", "public", "comment")

toks1 <- tokens_select(toks, pattern = add_stops, selection = "remove")
```

# Convert EPA Corpus Tokens to a Document-Feature Matrix

```{r}
# convert tokens to dfm
dfm_comm <- dfm(toks1, tolower = TRUE)

# stem words in dfm
dfm <- dfm_wordstem(dfm_comm)

# remove terms only appearing in one doc (min_termfreq = 10)
dfm <- dfm_trim(dfm, min_docfreq = 2) 

# remove rows (docs) with all zeros
sel_idx <- slam::row_sums(dfm) > 0 

# comments_df <- dfm[sel_idx, ]
dfm <- dfm[sel_idx, ]

```

## Calculate metrics from the data 

### CaoJuan 2009 & Deveaud2014 method 

```{r}
result_cjD <- FindTopicsNumber(dfm,
                           topics = seq(from = 2, to = 20, by = 1),
                           metrics = c("CaoJuan2009",  "Deveaud2014"),
                           method = "Gibbs",
                           control = list(seed = 77),
                           verbose = TRUE)

FindTopicsNumber_plot(result_cjD)
```

With the CaoJuan 2009 & Deveaud2014 method, it seems like 9 topics is the ideal number. 

### CaoJuan2009 & Griffiths2004 Method 

```{r}
result_cjG <- FindTopicsNumber(dfm,
                               topics = seq(from = 2, to = 20, by = 1),
                               metrics = c("CaoJuan2009", "Griffiths2004"),
                               method = "Gibbs",
                               control = list(seed = 77),
                               verbose = TRUE)

FindTopicsNumber_plot(result_cjG)
```

With the CaoJuan 2009 & Deveaud2014 method, it seems like either 5 or 9 topics could be the ideal number. 


# Latent Dirichlet Allocation (LDA) Modelling 

## Model 1: k = 7

Choosing 7 as it lies between 5 topics and 9 topics as a reference

```{r, model1}
# select topic areas and assign to 'k'
k <- 7 

# running LDA function, telling it how many topics to look for (9), est. 2 matrices

topicModel_k7 <- LDA(dfm, 
                     k, 
                     method="Gibbs",
                     control=list(iter = 500, verbose = 25))

```

## Model Results

```{r, examplemodel7_results}
# LDA estimated topics, saved result
tmResult1 <- posterior(topicModel_k7)

# beta matrix from results
beta1 <- tmResult1$terms   

# 
terms(topicModel_k7, 10)
```

## Visualize Model Results

```{r}
svd_tsne <- function(x) tsne(svd(x)$u)

json1 <- createJSON(
  phi = tmResult1$terms, 
  theta = tmResult1$topics, 
  doc.length = rowSums(dfm), 
  vocab = colnames(dfm), 
  term.frequency = colSums(dfm),
  mds.method = svd_tsne,
  plot.opts = list(xlab="", ylab=""))

serVis(json1)
```

## Model 2: k = 5

```{r, model2}
# select topic areas and assign to 'k'
k <- 5 

# running LDA function, telling it how many topics to look for (9), est. 2 matrices

topicModel_k5 <- LDA(dfm, 
                     k, 
                     method="Gibbs",
                     control=list(iter = 500, verbose = 25))

```

## Model Results

```{r, model2_results}
# LDA estimated topics, saved result
tmResult2 <- posterior(topicModel_k5)

# beta matrix from results
beta2 <- tmResult2$terms   

# 
terms(topicModel_k5, 10)
```

## Visualize Model Results

```{r, model2_visualize}
svd_tsne <- function(x) tsne(svd(x)$u)

json2 <- createJSON(
  phi = tmResult2$terms, 
  theta = tmResult2$topics, 
  doc.length = rowSums(dfm), 
  vocab = colnames(dfm), 
  term.frequency = colSums(dfm),
  mds.method = svd_tsne,
  plot.opts = list(xlab="", ylab=""))

serVis(json2)
```

## Model 3: k = 9

```{r, model3}
# select topic areas and assign to 'k'
k <- 9 

# running LDA function, telling it how many topics to look for (9), est. 2 matrices

topicModel_k9 <- LDA(dfm, 
                     k, 
                     method="Gibbs",
                     control=list(iter = 500, verbose = 25))

```

## Model Results

```{r, model3_results}
# LDA estimated topics, saved result
tmResult3 <- posterior(topicModel_k9)

# beta matrix from results
beta3 <- tmResult3$terms   

# 
terms(topicModel_k9, 10)
```

## Visualize Model Results

```{r, model3_visual}
svd_tsne <- function(x) tsne(svd(x)$u)

json3 <- createJSON(
  phi = tmResult3$terms, 
  theta = tmResult3$topics, 
  doc.length = rowSums(dfm), 
  vocab = colnames(dfm), 
  term.frequency = colSums(dfm),
  mds.method = svd_tsne,
  plot.opts = list(xlab="", ylab=""))

serVis(json3)
```

## Top Topic Terms for Model 2: k = 5 

```{r, top terms 5}
comment_topics <- tidy(topicModel_k5, matrix = "beta")

top_terms <- comment_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

```

```{r}
top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()
```

## Top Topic Terms for Model 3: k = 9

```{r, top terms 9}
comment_topics9 <- tidy(topicModel_k9, matrix = "beta")

top_terms9 <- comment_topics9 %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

```

```{r}
top_terms9 %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()
```

## Result Response

It seems like 5 topics is the best selection due to the distance between each topic groups in the `json servis` visualization. When plotting the top topic terms, 5 topics also seems like clearer divisions than 9 topics. 
